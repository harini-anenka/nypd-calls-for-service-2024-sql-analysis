# NYPD Calls for Service – 2024 Q1 to Q3 Analysis


## **📌 Project Overview**
This project analyzes the NYPD Calls for Service (2024 Q1–Q3) dataset obtained from [NYC Open Data](https://opendata.cityofnewyork.us/)

This dataset documents entries into the NYPD 911 system, ICAD. The data is collected from the ICAD system which call takers and dispatchers use to communicate with callers and the NYPD. Each record represents an entry into the system. The data includes entries generated by members of the public as well as self-initiated entries by NYPD Members of Service. The data can be used for issues being responded to by the NYPD.


## **📄Data Source**

**Dataset**: [NYPD Calls for Service (Year‑to‑Date)](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data)

**Period covered**: Q1–Q3 2024 (Jan–Sep)

**Grain**: One record per 911 call / CAD event

**Size**: ~5 million rows (2024 Q1–Q3)

**Columns**: 18 fields


## **🔧Tools**

**Database** → [PostgreSQL](https://www.postgresql.org/)

**SQL Client / IDE** → [DBeaver](https://dbeaver.io/)


## **🛠 Data Preparation**

**Backup & Import** – Always maintained a backup copy before loading.

**Schema Adjustments** – Fixed incorrect datetime datatypes by altering and updating columns.

**Duplicate Handling** – Identified and removed duplicate rows.

**Null Values** – For a datetime column with heavy nulls, replaced them with meaningful placeholders using aggregation instead of dropping.
For smaller sets of nulls (e.g., unknown locations), kept them since “Unknown” can itself be a valid category to monitor.

**Standardization** – Split certain columns by delimiter for cleaner grouping and easier readability.

👉 All preparation steps are documented in the attached Data Preparation & Cleaning files.


## **📊 Analysis Approach**

After cleaning, I performed:

Descriptive Analysis → to understand overall distributions and trends.

Ad-hoc Analysis (Operational Use Cases) → answering targeted questions to reveal patterns in precinct activity, call types, and time-of-day variations.


## **🔍 Ad-hoc Analysis (Operational Use Cases)**

### Each query was framed as a question, followed by an operational use case.

1. Trend in Call Volumes Over Time – Are calls increasing or decreasing weekly?

2. Peak Incident Hours – When do call volumes spike during the day?

3. Top Precincts by Call Volume – Which areas receive the highest service demand?

4. Repeat Callers / Frequent Addresses – Are certain locations repeatedly calling?

5. Call Type Evolution – Have specific incident types increased or decreased over time?

6. Incident Volume Deviation Detection – Are there precincts with sudden spikes/drops in weekly call volumes?

7. Top Call Types by Geographic Spread – Which incident types occur across the widest area?

8. Day vs. Night Call Patterns – Which radio codes are more frequent during the day vs. night?

👉 Detailed insights with sample outputs and screenshots are available in the attached Ad-hoc & Descriptive Analysis Doc.


## **🔹 Next Steps / Suggestions**

Automate updates by connecting directly to the API.

Expand transformations (e.g., more granular column standardization).

Build a visualization dashboard (Tableau / Power BI) for dynamic analysis.
